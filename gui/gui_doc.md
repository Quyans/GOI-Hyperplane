# GUI Doc

# 1. Running

```bash
python gui/main.py --config gui/configs/default.yaml
```

You can specify GUI config file using `--config` option. Please refer to `gui/configs/default.yaml` for details of the configurations.

You can also modify certain configuration via the command line, which will override the settings specified in the config file.

```bash
python gui/main.py --config gui/configs/default.yaml load='output/room/point_cloud/iteration_1500'
```

![The GUI appearance](assets/app.png)

The GUI appearance

# 2. Usage

## Visualization and Interaction

After loading the GUI, you can explore the reconstructed scene using the `WASD` keys for movement and `QE` for vertical navigation. If the scene appears upside down, press `T` to **flip** it.

You can also use mouse drag to **rotate** the camera and the scroll wheel to zoom in or out.

In the `>>Initialize` config section, you can load “new scenes” (**scene models** only) and “new eval data” (importing **cameras** from another dataset) by entering the path in the provided box, without needing to reload the window.

In the `>>Rendering` section at the bottom, you can switch the rendering **mode** (such as depth and alpha of the image) and select a rendering **pose** from the dataset's camera.

## Text Querying

In the `>>Query` section, you can search for objects in the scene using text prompts.

To start, press `init` to load the VLM. Note: this process may take some time, but it's handled in a separate thread, allowing you to continue exploring the scene. The command line will notify you when the process is complete.

### **1) Vanilla Querying**

Type the prompt in the `CLIP` box, and press Enter to initiate the option. The segmented area will be highlighted.

**Coloring Strategy**: By default, the segmentation result displays the original image overlaid with a color mask, with the background set to white and the object colored based on similarity to the query. Adjust the `ratio` slider (found in `>>Initialize` section) to control the balance between the original image and the colored mask.

There are two checkboxes on the right:

- Uncheck `coloring` to remove the object's color mask.
- Check `binary` to display a binary 0-1 mask, which can be saved for further evaluation.

### 2) OSH fine-tuning

To use the OSH method proposed in our paper, you should start by performing a basic query. Then follow these steps:

1. Set a viewing pose.
2. Copy the same text prompt into the `RES` box.
3. Press `show_res_masks` to display the mask generated by the RES model, allowing you to verify if the model is functioning correctly.
4. Press `res_loc` to optimize the OSH.

Once completed, the highlighted object will be visible. To search for another object, press `refresh` to reset the OSH.

## Scene Editing

### **1) Object Manipulation**

In the `>>Editing` section, the GUI allows 3D object manipulation based on the text query.
Press `retrieve` to perform 3D segmentation using features embedded in Gaussian primitives, getting in 3D **Gaussians of Interest** without altering the scene's appearance.

Afterward, you can use the `UOIJKL` keys to move the foreground object along the coordinate axes. For further operations, press `seg` to segment the object or `del` to delete it. These actions are reversible by pressing `reset`, which restores all objects to their original positions. To exit the retrieval process and return to the original scene, press `exit`.

### **2) Inpainting**

TBD

# 3. About Evaluation

### Save Picture

In the `>>Query` section, there is a save button and a text box. The image on the left will be saved with the name provided in the text box. The full path will be `<outdir>/<save_path>/<img_name>.png`. The `outdir` and `save_path` are defined in the configuration file, while the `save_path` and `img_name` can be modified directly within the GUI in the two available text boxes.

![image.png](assets/inbox.png)

### Eval configuration

During evaluation, follow the complete querying process and save the image in `binary` mode. Since our work uses a 2D RES model, you'll need to manually save the 2D masks. Ensure that the data paths are organized for future testing, including the scene name, prompt, and corresponding image name from the dataset (e.g. *exp/room/sofa_in_dark_green/DSCF4667.png*).

For best results, adjust the GUI resolution to match the evaluation data, though the evaluation code can resize the mask if necessary.